---
output: pdf_document
header-includes:
   - \usepackage{tcolorbox}
   - \usepackage{fancyhdr}
   - \usepackage[utf8]{inputenc}
urlcolor: blue
---

\pagestyle{fancy}
\fancyhf{}
\rhead{Will Nickols}
\lhead{Section 10}
\rfoot{Page \thepage}

# Announcements
- Make sure to sign in on the [google form](https://forms.gle/JGvZP8CPUhaefnLT6)
- Pset 9 due December 2 at 5 pm
- Final project due Wednesday December 14th at 5 pm

```{r, echo=F, warning=F, message=F}
library(lme4)
library(ggplot2)
library(reshape2)
library(gridExtra)
library(dplyr)
library(MASS)
library(nlme)
```

# Many ways to ~~skin a cat~~ [peel an orange](https://www.peta.org/features/animal-friendly-idioms/)

Recall the following linear model extensions:

- Heteroscedasticity-consistent standard errors: $\vec{Y}=\mathbf{X}\vec{\beta}+\vec{\epsilon}$, $\epsilon\sim MVN(\vec{0}, \vec{\sigma^2}\mathbf{I}_{n\times n})$ where $\vec{\sigma}^2$ has non-identical entries
- Weighted least squares: $\vec{Y}=\mathbf{X}\vec{\beta}+\vec{\epsilon}$, $\epsilon\sim MVN(\vec{0},\mathbf{W}^{-1}\sigma^2\mathbf{I}_{n\times n})$ where $\mathbf{W}$ is a diagonal matrix of weights
- Huber's method: Minimize $\textrm{loss}=\sum_{i}^ng(\hat\epsilon_i)$ with $$g(x)=\begin{cases} 
      x^2/2 & |x|<c \\
      c|x| - c^2/2 & |x|\geq c
      \end{cases}$$
- Block correlations: $\vec{Y}=\mathbf{X}\vec{\beta}+\vec{\epsilon}$, $\epsilon\sim MVN(\vec{0}, \mathbf{\Sigma})$ with a covariance matrix like $$\mathbf{\Sigma}=\begin{bmatrix}
1 & \rho_1 & \rho_1 & 0 & 0 \\
\rho_1 & 1 & \rho_1 & 0 & 0 \\
\rho_1 & \rho_1 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 & \rho_2 \\
0 & 0 & 0 & \rho_2 & 1 \\
\end{bmatrix}	$$
- Autoregressive: $\vec{Y}=\mathbf{X}\vec{\beta}+\vec{\epsilon}$, $\epsilon\sim MVN(\vec{0}, \mathbf{\Sigma})$ with a covariance matrix like $$\mathbf{\Sigma}=\begin{bmatrix}
1 & \rho & \rho^2 & \rho^3 & \rho^4 \\
\rho & 1 & \rho & \rho^2 & \rho^3 \\
\rho^2 & \rho & 1 & \rho & \rho^2 \\
\rho^3 & \rho^2 & \rho & 1 & \rho \\
\rho^4 & \rho^3 & \rho^2 & \rho & 1 \\
\end{bmatrix}	$$
- Random intercepts: $Y_{ij}\sim\alpha + \alpha_i+\beta X_{ij}+\epsilon_{ij}$ with $\epsilon_{ij}\sim\mathcal{N}(0, \sigma^2_Y)$ and $\alpha_i\sim\mathcal{N}(0, \sigma^2_\alpha)$.  (Note that this version explicitly includes a fixed slope and a random slope with mean 0.  Random effects as you'll see them elsewhere (and in `lmer`) are usually specified to have mean 0, so including the fixed effect separately is a good practice.)
- Random slopes: $Y_{ij}\sim\alpha +(\beta + \beta_i)X_{ij}+\epsilon_{ij}$ with $\epsilon_{ij}\sim\mathcal{N}(0, \sigma^2_Y)$ and $\beta_i\sim\mathcal{N}(0, \sigma^2_\beta)$.

1. For each of the scenarios below, which of the above linear model extensions would you use?

- Stock price over a week: 
- Wheat yield vs phosphorus fertilizer use in various Kansas counties: 
- Soil nitrate concentration vs fertilizer use where the nitrate measurements are taken with instruments of varying precision:
- Spotify listens vs release year:
- Day in year leaves start to fall vs latitude for various tree types:

2. Which line is which in the following models?

- One line is a standard OLS; the other uses weighted regression.

```{r, message=F, echo=F, fig.height=3, fig.width=6}
readRDS(file = "plot1.RDS")
```

- One line is a standard OLS; the other uses Huber's method.

```{r, message=F, echo=F, fig.height=3, fig.width=6}
readRDS(file = "plot2.RDS")
```

- One line is a standard OLS; the other uses autoregression.

```{r, message=F, echo=F, fig.height=3, fig.width=6}
readRDS(file = "plot3.RDS")
```

\newpage

# Meta-analysis analysis

One common use of mixed effects models is in meta-analysis to aggregate the results of multiple studies.  This question will explore various methods of meta-analysis aggregation.

1. A common plot in meta-analysis is a forest plot, showing the mean and standard deviation of some quantity of interest as determined by various studies as well as an aggregated mean and variance.  Given the following forest plots (technically these are axis-flipped forest plots), determine what a linear mixed effects model combining the studies should look like.

```{r, cache=T, echo=F, warning=F}
# Version 1

set.seed(1)

true_effect = 1
n_studies = 9

# Effects observed in each study
study_effects = rnorm(n_studies, true_effect, 0.1)

# Number of participants in each study
study_ns = floor(rpois(n_studies, 50))

# Stores all x and y observations and the study they come from
df = matrix(nrow = 0, ncol = 3)

# Stores mean, sd, n for each study
stats_df = matrix(nrow = n_studies, ncol = 4)

for (i in 1:n_studies) {
  study_n = study_ns[i]
  xs = rnorm(study_n, 0, 1)
  ys = rnorm(study_n, xs * study_effects[i], 2)
  df = rbind(df, cbind(xs, ys, study = rep(i, study_n)))
  stats_df[i, 1:2] = summary(lm(ys ~ xs))$coefficients[2, 1:2]
  stats_df[i, 3] = study_n
}
stats_df[1:nrow(stats_df), 4] = 1:n_studies

df = data.frame(df)

# Fit meta-analysis lmer
lmer1 = suppressMessages(lmer(ys ~ xs + (xs - 1 || study), data = df))

stats_df = data.frame(stats_df)
colnames(stats_df) = c("mean", "sd", "n", "study")
stats_df$study <- as.character(stats_df$study)

stats_df[nrow(stats_df) + 1, ] = c(NA, NA, NA, NA) #c(summary(lmer1)$coefficients[2, 1:2], NA, NA)
stats_df[nrow(stats_df), 4] = "Mixed effects"

plot1 <- ggplot(stats_df, aes(x=study, y=mean)) + 
  geom_point()+
  geom_errorbar(aes(ymin=mean-2*sd, ymax=mean+2*sd), width=.2,
                position=position_dodge(0.05)) + 
  ylab("Mean +/- 2 StDev") + 
  xlab("Study")

# Version 2

# Effects observed in each study
study_effects = rnorm(n_studies, true_effect, 2)

# Number of participants in each study
study_ns = floor(rpois(n_studies, 50))

# Stores all x and y observations and the study they come from
df = matrix(nrow = 0, ncol = 3)

# Stores mean, sd, n for each study
stats_df = matrix(nrow = n_studies, ncol = 4)

for (i in 1:n_studies) {
  study_n = study_ns[i]
  xs = rnorm(study_n, 0, 1)
  ys = rnorm(study_n, xs * study_effects[i], 1)
  df = rbind(df, cbind(xs, ys, study = rep(i, study_n)))
  stats_df[i, 1:2] = summary(lm(ys ~ xs))$coefficients[2, 1:2]
  stats_df[i, 3] = study_n
}
stats_df[1:nrow(stats_df), 4] = 1:n_studies

df = data.frame(df)

# Fit meta-analysis lmer
lmer1 = suppressMessages(lmer(ys ~ xs + (xs - 1 || study), data = df))

stats_df = data.frame(stats_df)
colnames(stats_df) = c("mean", "sd", "n", "study")
stats_df$study <- as.character(stats_df$study)

stats_df[nrow(stats_df) + 1, ] = c(NA, NA, NA, NA) #c(summary(lmer1)$coefficients[2, 1:2], NA, NA)
stats_df[nrow(stats_df), 4] = "Mixed effects"

plot2 <- ggplot(stats_df, aes(x=study, y=mean)) + 
  geom_point()+
  geom_errorbar(aes(ymin=mean-2*sd, ymax=mean+2*sd), width=.2,
                position=position_dodge(0.05)) + 
  ylab("Mean +/- 2 StDev") + 
  xlab("Study")

grid.arrange(plot1, plot2, nrow=2)
```

2. Sometimes, studies will not make available all their individual data points.  In these cases, we might only have a point estimate and standard error for a particular statistic of interest.  Assume that for study $i$ we have our statistic of interest $$\hat\beta_i\sim\mathcal{N}(\beta,\sigma_{\hat\beta_i}^2)$$ where we will approximate the true standard error $\sigma_{\hat\beta_i}^2$ with our estimated standard error $\hat\sigma_{\hat\beta_i}^2$.  This model specifies that there is some underlying effect $\beta$ and that each study will find some $\hat\beta_i$ with a standard error based on the study's sample size etc.  Assuming we have $n_{\textrm{studies}}$, use maximum likelihood estimation to find a point estimate for $\beta$.

3. The code below simulates data from one of two scenarios.  In the first scenario, there is a true effect $\beta$ that holds in all the studies.  The only thing that differs by study is the sample size.  Therefore, for study $i$, the $j^{th}$ observation is given by $Y_{ij}=\beta_0 + \beta X_{ij}+\epsilon_{ij}$ with $\epsilon_{ij}\sim\mathcal{N}(0, \sigma_Y^2)$.  In the second scenario, the effect in study $i$ is $\beta_i\sim\mathcal{N}(\beta, \sigma_\beta^2)$.  Then, for study $i$, the $j^{th}$ observation is given by $Y_{ij}=\beta_0 + \beta_i X_{ij}+\epsilon_{ij}$ with $\epsilon_{ij}\sim\mathcal{N}(0, \sigma_Y^2)$.

We will consider 5 methods:

- Use the likelihood method above
- Find $\hat\beta_i$ for each study and take the average to estimate $\beta$.
- Use a mixed effects model `ys ~ xs + (xs - 1 | study)` (random slopes, no random intercepts)
- Combine all the data points and run a linear model with `ys ~ xs`
- Combine all the data points and run a linear model with `ys ~ xs + xs:as.factor(study_id)`

Interpret the outputs: how do the methods perform on the two scenarios? (The code below should be cached and takes a while to run, so don't change it unnecessarily.)

```{r, warning=F, cache=T, echo=F}
set.seed(139)

nsims = 1000

output_df = matrix(nrow = nsims, ncol = 5)

true_effect = 1
n_studies = 9
b_0 = 120

for (nsim in 1:nsims) {
  # size of studies
  study_ns = floor(rexp(n_studies, 1/50)) + 10
  
  df = matrix(nrow = 0, ncol = 3)
  stats_df = matrix(nrow = n_studies, ncol = 4)
  
  for (i in 1:n_studies) {
    study_n = study_ns[i]
    xs = rnorm(study_n, 0, 1)
    ys = b_0 + rnorm(study_n, xs * true_effect, 10)
    df = rbind(df, cbind(xs, ys, study = rep(i, study_n)))
    stats_df[i, 1:2] = summary(lm(ys ~ xs))$coefficients[2, 1:2]
    stats_df[i, 3] = study_n
  }
  stats_df[1:nrow(stats_df), 4] = 1:n_studies
  
  df = data.frame(df)
  
  lmer1 = suppressMessages(lmer(ys ~ xs + (xs - 1 | study), data = df))

  stats_df = data.frame(stats_df)
  colnames(stats_df) = c("mean", "sd", "n", "study")
  stats_df$study <- as.character(stats_df$study)
  
  stats_df[nrow(stats_df) + 1, ] = list(sum(stats_df$mean/stats_df$sd)/sum(1/stats_df$sd), NA, NA, NA)
  stats_df[nrow(stats_df), 4] = "Likelihood"
  
  stats_df[nrow(stats_df) + 1, ] = list(mean(stats_df$mean), NA, NA, NA)
  stats_df[nrow(stats_df), 4] = "Raw means"
  
  stats_df[nrow(stats_df) + 1, ] = c(summary(lmer1)$coefficients[2, 1:2], NA, NA)
  stats_df[nrow(stats_df), 4] = "Mixed effects"
  
  stats_df[nrow(stats_df) + 1, ] = c(summary(lm(ys ~ xs + xs:as.factor(study), data = df))$coefficients[2, 1:2], NA, NA)
  stats_df[nrow(stats_df), 4] = "Fixed effects with interactions"
  
  stats_df[nrow(stats_df) + 1, ] = c(summary(lm(ys ~ xs, data = df))$coefficients[2, 1:2], NA, NA)
  stats_df[nrow(stats_df), 4] = "Fixed effects no interactions"
  
  output_df[nsim, ] = stats_df[n_studies + (1:5), 1]
  
  # if (nsim %% 100 == 0) {
  #   print(paste0(nsim/nsims * 100, "% done"))
  # }
}

output_df = melt(output_df)
colnames(output_df) <- c("Index", "Method", "Beta")
output_df$Method <- case_when(output_df$Method == 1 ~ "1. Likelihood",
                              output_df$Method == 2 ~ "2. Raw means",
                              output_df$Method == 3 ~ "3. Linear mixed effects",
                              output_df$Method == 4 ~ "4. Fixed effects with interaction",
                              output_df$Method == 5 ~ "5. Fixed effects no interaction")

#ggplot(output_df, aes(x=Beta, fill=Method)) + 
#  geom_histogram(alpha=0.5, position="identity", binwidth = 0.1)

comparison_df = data.frame(matrix(nrow = 5, ncol = 4))
comparison_df[, 1] = c("Likelihood", "Raw means", "Linear mixed effects", "Fixed effects with interaction", "Fixed effects no interaction")
comparison_df[, 2] = as.numeric(by(output_df$Beta, output_df$Method, mean))
comparison_df[, 3] = as.numeric(by(output_df$Beta, output_df$Method, sd))
comparison_df[, 4] = c(sum((output_df$Beta[output_df$Method=="1. Likelihood"] - true_effect)^2),
                       sum((output_df$Beta[output_df$Method=="2. Raw means"] - true_effect)^2),
                       sum((output_df$Beta[output_df$Method=="3. Linear mixed effects"] - true_effect)^2),
                       sum((output_df$Beta[output_df$Method=="4. Fixed effects with interaction"] - true_effect)^2),
                       sum((output_df$Beta[output_df$Method=="5. Fixed effects no interaction"] - true_effect)^2)) / nsims
colnames(comparison_df) <- c("Method", "Mean", "SD", "MSE")

comparison_df
```

```{r, warning=F, cache=T, echo=F}
set.seed(139)

nsims = 1000

output_df = matrix(nrow = nsims, ncol = 5)

true_effect = 1
n_studies = 9
b_0 = 120

for (nsim in 1:nsims) {
  # beta_i
  study_effects = rnorm(n_studies, true_effect, 2)
  
  # size of studies
  study_ns = floor(rexp(n_studies, 1/50)) + 10
  
  df = matrix(nrow = 0, ncol = 3)
  stats_df = matrix(nrow = n_studies, ncol = 4)
  
  for (i in 1:n_studies) {
    study_n = study_ns[i]
    xs = rnorm(study_n, 0, 1)
    ys = b_0 + rnorm(study_n, xs * study_effects[i], 10)
    df = rbind(df, cbind(xs, ys, study = rep(i, study_n)))
    stats_df[i, 1:2] = summary(lm(ys ~ xs))$coefficients[2, 1:2]
    stats_df[i, 3] = study_n
  }
  stats_df[1:nrow(stats_df), 4] = 1:n_studies
  
  df = data.frame(df)
  
  lmer1 = suppressMessages(lmer(ys ~ xs + (xs - 1 | study), data = df))

  stats_df = data.frame(stats_df)
  colnames(stats_df) = c("mean", "sd", "n", "study")
  stats_df$study <- as.character(stats_df$study)
  
  stats_df[nrow(stats_df) + 1, ] = list(sum(stats_df$mean/stats_df$sd)/sum(1/stats_df$sd), NA, NA, NA)
  stats_df[nrow(stats_df), 4] = "Likelihood"
  
  stats_df[nrow(stats_df) + 1, ] = list(mean(stats_df$mean), NA, NA, NA)
  stats_df[nrow(stats_df), 4] = "Raw means"
  
  stats_df[nrow(stats_df) + 1, ] = c(summary(lmer1)$coefficients[2, 1:2], NA, NA)
  stats_df[nrow(stats_df), 4] = "Mixed effects"
  
  stats_df[nrow(stats_df) + 1, ] = c(summary(lm(ys ~ xs + xs:as.factor(study), data = df))$coefficients[2, 1:2], NA, NA)
  stats_df[nrow(stats_df), 4] = "Fixed effects with interactions"
  
  stats_df[nrow(stats_df) + 1, ] = c(summary(lm(ys ~ xs, data = df))$coefficients[2, 1:2], NA, NA)
  stats_df[nrow(stats_df), 4] = "Fixed effects no interactions"
  
  output_df[nsim, ] = stats_df[n_studies + (1:5), 1]
  
  # if (nsim %% 100 == 0) {
  #   print(paste0(nsim/nsims * 100, "% done"))
  # }
}

output_df = melt(output_df)
colnames(output_df) <- c("Index", "Method", "Beta")
output_df$Method <- case_when(output_df$Method == 1 ~ "1. Likelihood",
                              output_df$Method == 2 ~ "2. Raw means",
                              output_df$Method == 3 ~ "3. Linear mixed effects",
                              output_df$Method == 4 ~ "4. Fixed effects with interaction",
                              output_df$Method == 5 ~ "5. Fixed effects no interaction")

#ggplot(output_df, aes(x=Beta, fill=Method)) + 
#  geom_histogram(alpha=0.5, position="identity", binwidth = 0.1)

comparison_df = data.frame(matrix(nrow = 5, ncol = 4))
comparison_df[, 1] = c("Likelihood", "Raw means", "Linear mixed effects", "Fixed effects with interaction", "Fixed effects no interaction")
comparison_df[, 2] = as.numeric(by(output_df$Beta, output_df$Method, mean))
comparison_df[, 3] = as.numeric(by(output_df$Beta, output_df$Method, sd))
comparison_df[, 4] = c(sum((output_df$Beta[output_df$Method=="1. Likelihood"] - true_effect)^2),
                       sum((output_df$Beta[output_df$Method=="2. Raw means"] - true_effect)^2),
                       sum((output_df$Beta[output_df$Method=="3. Linear mixed effects"] - true_effect)^2),
                       sum((output_df$Beta[output_df$Method=="4. Fixed effects with interaction"] - true_effect)^2),
                       sum((output_df$Beta[output_df$Method=="5. Fixed effects no interaction"] - true_effect)^2)) / nsims
colnames(comparison_df) <- c("Method", "Mean", "SD", "MSE")

comparison_df
```

4. Under the random slopes model specified above, given a new $X$ from a new study, find the probability that its associated $Y$ value will be less than $\tau$.

\newpage

# Crops continued

This question will deal with a data set of country-level statistics from [this source](https://www.gu.se/en/quality-government/qog-data/data-downloads/standard-dataset) with an explanation of the data encoding found [here](https://www.qogdata.pol.gu.se/data/codebook_std_jan22.pdf).  

A few useful columns:

- `mad_gdppc`: GDP per capita
- `wdi_araland`: Arable land (\% of land area)
- `wdi_precip`: Average annual precipitation (mm per year)
- `ht_region`: Country's region of the world: Eastern Europe (1), Latin America (2), North Africa & the Middle East (3), Sub-Saharan Africa (4), Western Europe and North America (5), East Asia (6), South-East Asia (7), South Asia (8), Pacific (9), Caribbean (10)

```{r, include=F}
countries <- read.csv("data/countries.csv")
```

1. Fit a quadratic regression model to predict `wdi_araland` from `wdi_precip`, using `log(mad_gdppc)` as a weight to account for the fact that wealthier countries might have more accurate crop tracking technology.  Call this `lm_weight`.

```{r}
# TODO: Fit lm_weight
```

2. Use the `lmer` function to fit a mixed effects model with a random intercept based on the country's `ht_region`, and use the argument `weight=log(mad_gdppc)` here as well.  Call this `lmer1`.

```{r}
# TODO: Fit lmer1
```
3. Use your models to plot the estimated relationship between precipitation and arable land.

```{r, warning=F, echo=F, eval=F}
# Due to my loathing of base R plots, this chunk of code is devoted to creating dummy ranges 
# of precipitation values so that each model can show a curve

dummy_x <- seq(min(countries$wdi_precip, na.rm = T), max(countries$wdi_precip, na.rm=T), 1)
lm_unweighted <- lm(wdi_araland~poly(wdi_precip, 2, raw = TRUE), countries)
lm_unweighted_pred <- predict(lm_unweighted, newdata=data.frame(wdi_precip = dummy_x))
lm_weighted_pred <- predict(lm_weight, newdata=data.frame(wdi_precip = dummy_x))
countries_subset <- countries[!is.na(countries$wdi_precip) & 
                                !is.na(countries$wdi_araland) & 
                                !is.na(countries$mad_gdppc),]

# Trying to get the region weighting reasonable
lmer_pred <- predict(lmer1, newdata=data.frame(wdi_precip = rep(dummy_x, 9), 
                                               ht_region = rep(as.factor(c(1:8, 10)), each=length(dummy_x))
                                               ))
lmer_pred <- matrix(lmer_pred, ncol = 9)
lmer_pred <- as.vector(lmer_pred %*% as.matrix(unname(table(countries_subset$ht_region)/sum(table(countries_subset$ht_region)))[c(1:8, 10)]))

dummy_df <- data.frame(dummy_x, "Unweighted linear model" = lm_unweighted_pred, 
                       "Weighted linear model" = lm_weighted_pred, 
                       "Mixed effects model" = lmer_pred, check.names = F)
dummy_df <- melt(dummy_df, id.vars="dummy_x")
colnames(dummy_df) = c("dummy_x", "Model", "value")

ggplot(countries, aes(x=wdi_precip, y=wdi_araland)) + 
  geom_point() + 
  geom_line(data=dummy_df, aes(y=value, x=dummy_x, col=Model), size=0.5) + 
  xlab("Average annual precipitation (mm per year)") + 
  ylab("Arable land (% of land area)")
```
