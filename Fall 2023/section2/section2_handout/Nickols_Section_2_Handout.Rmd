---
output:
  pdf_document: default
  html_document:
    df_print: paged
header-includes:
- \usepackage{tcolorbox}
- \usepackage{fancyhdr}
- \usepackage[utf8]{inputenc}
- \usepackage{wrapfig}
- \usepackage{amsmath}
- \usepackage{booktabs}
- \usepackage{esvect}
urlcolor: blue
---

\pagestyle{fancy}
\fancyhf{}
\rhead{Will Nickols}
\lhead{Section 2}
\rfoot{Page \thepage}

# Announcements

\begin{wrapfigure}{r}{0.12\textwidth}
  \centering
    \vspace*{-1.3cm}
    \includegraphics[width=\linewidth]{section_qr_code.png}
\end{wrapfigure}

Make sure to sign in on the [google form](https://forms.gle/xm1DfzuZFNcWU6fH8) (I send a list of which section questions are useful for which pset questions afterwards)

Pset 1 due Friday 9/22

# Introductions (again)
- Name
- One question or thought related to lecture last week (ANOVA, $F$-test, ranks)

```{r, echo=F, warning=F, message=F, cache=F}
list.of.packages <- c("ggplot2", "gridExtra", "MASS", "dplyr")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library(ggplot2)
library(gridExtra)
library(dplyr)
```

# Manipulating new distributions

Let $T_n\sim t_n$. Find the following:

1. Distribution of $T_n^2$. Hint: Think about the representation of $T_n$.

\vspace{2 cm}

2. Distribution of $T^{-2}$

\vspace{1 cm}

3. Let $X_1,...,X_n\sim\textrm{Expo}(\alpha)$. Find the $k$ (in terms of $\alpha$) such that $k\sum_{i=1}^nX_i\sim\chi^2_{2n}$.

\vspace{2 cm}

\newpage

# Simulations

1. Let $X_1, X_2,\dots, X_n\sim \mathcal{N}(\mu, \sigma^2)$. Then, let $X_{i,1}=X_i+\epsilon_{i,1}$ and $X_{i,2}=X_i+\beta+\epsilon_{i,2}$ with $\epsilon_{i,j}\sim\mathcal{N}(0,\sigma^2)$. Suppose we simulate many paired and unpaired $t$-tests for the difference in the mean of the $X_{i,1}$s vs. the mean of the $X_{i,2}$s. If $\beta$ is non-zero, which color is the paired $t$-test?

```{r, echo=F, fig.width=5, fig.height=3, fig.align='center', cache=T, warning=F}
n = 10
beta = 1
nsim = 1000

paired_vec = vector(length = nsim)
unpaired_vec = vector(length = nsim)
for (i in 1:nsim) {
  x = rnorm(n, 10, 3)
  x_1 = x + rnorm(n, 5, 3)
  x_2 = x + beta + rnorm(n, 0, 3)
  paired_vec[i] = t.test(x_1-x_2)$statistic
  unpaired_vec[i] = t.test(x_1, x_2)$statistic
}

df = data.frame("t-stat" = c(paired_vec, unpaired_vec), 
                "paired" = c(rep("Paired", nsim), rep("Unpaired", nsim)), check.names = F)

ggplot(df, aes(x=`t-stat`, fill=paired)) + 
  geom_histogram(alpha=0.4, position="identity", bins = 30) + 
  theme_bw() + 
  ylab("Count") +
  theme(legend.position = "none")
```

\vspace{1 cm}

2. Suppose we have some $\beta_i$ for $i\in\{1,...,n_\beta\}$ that are not equal. Let $X_{i,j}=\beta_i+\epsilon_{i,j}$ for $j=1$ to $n$ with $\epsilon_{i,j}\sim\mathcal{N}(0, \sigma^2)$. We want to test whether $\beta_1=\beta_2=\dots=\beta_{n_\beta}$. We'll run a simulation in which we consider two cases:
- In the first case, we use the proper groupings of the $X_{i,j}$; that is, there are $n$ observations in each group, all with the same $\beta_i$.
- In the second case, we'll subdivide each of these groups into 2 so that there are $n/2$ observations in each group with two groups for each $\beta_i$.

We'll run an ANOVA in each case and repeat this many times. Which color is which case?

```{r, echo=F, fig.width=5, fig.height=3, fig.align='center', cache=T, warning=F}
nsim = 1000
n_1 = 10
n_2 = 30
n_3 = 2
betas = 1:n_1

f_correct = vector(length = nsim)
f_incorrect = vector(length = nsim)

for (i in 1:nsim) {
  df = data.frame(matrix(nrow = 0, ncol = 0))
  for (beta in betas) {
    x = beta + rnorm(n_2, 0, 5)
    df = rbind(df, cbind(x, beta))
  }
  df$beta <- as.factor(df$beta)
  f_correct[i] = summary(aov(x~beta, df))[[1]][1,'F value']
  df$beta = as.numeric(as.character(df$beta))
  df$beta = (df$beta - 1) * n_3 + rep(rep(0:(n_3-1), n_2/n_3), n_1)
  df$beta <- as.factor(df$beta)
  f_incorrect[i] = summary(aov(x~beta, df))[[1]][1,'F value']
}

df = data.frame("f-stat" = c(f_correct, f_incorrect), 
                "split" = c(rep("Correct", nsim), rep("Incorrect", nsim)), check.names = F)

ggplot(df, aes(x=`f-stat`, fill=split)) + 
  geom_histogram(alpha=0.4, position="identity", bins=30) + 
  theme_bw() + xlim(0, 30) + 
  ylab("Count") + 
  theme(legend.position = "none")
```

\vspace{2 cm}

3. Let $X_i\sim\mathcal{N}(0, 1)$ for $i$ from $1$ to $n$. Let $Y_i\sim -1+\textrm{Expo}(1)$ for $i$ from $1$ to $n$. Suppose we conduct a two-sided, one-sample $t$-test for $H_0:\mu=0$ vs. $H_a:\mu\neq 0$ and record the p-value. The plots below show p-values from simulations repeating this many times for the two distributions and $n=5$ or $n=20$. Identify which is which.

```{r, echo=F, fig.width=7, fig.height=3, fig.align='center', cache=T, warning=F}
set.seed(139)
nsims = 200000

out_df <- data.frame(matrix(nrow = 0, ncol = 2))

for (n in c(5, 20)) {
  out_df <- rbind(out_df, cbind(rep(paste0("Normal n=", n), nsims),
                                replicate(nsims, t.test(rnorm(n, 0, 1))$p.value)))
  out_df <- rbind(out_df, cbind(rep(paste0("Expo n=", n), nsims),
                                replicate(nsims, t.test(rexp(n, 1) - 1)$p.value)))
}
out_df <- data.frame(out_df)
colnames(out_df) <- c("Version", "P-value")
out_df$`P-value` <- as.numeric(out_df$`P-value`)

ggplot(out_df, aes(x=`P-value`)) + 
  facet_grid(cols = vars(Version)) + 
  geom_histogram(bins = 20) + 
  xlim(c(0,1)) + 
  theme_bw() + 
  ylab("Count") + 
  theme(strip.text.x = element_blank(),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

\vspace{0.5 cm}

4. Which of the two comparisons do you expect to have the lower p-value? The one with a larger difference in sample means or the one with more data points (40 vs 400)?

```{r, echo=F, fig.width=5, fig.height=3, fig.align='center', cache=T, warning=F}
set.seed(9)

df <- data.frame("comparison" = c(rep("Comparison 1", 40), rep("Comparison 2", 400)),
           "group" = c(rep("Group 1", 20), rep("Group 2", 20), rep("Group 1", 200), rep("Group 2", 200)),
           "values" = c(rnorm(20, 5.4, 3), rnorm(20, 6.4, 3), rnorm(200, 5, 3), rnorm(200, 5.5, 3)))

ggplot(df, aes(x=group, y=values)) + 
  facet_grid(cols = vars(comparison)) + 
  geom_boxplot(alpha=0.4, outlier.size = 0) + 
  xlab("Group") + 
  ylab("Value") + 
  theme_bw() + 
  geom_jitter(color="black", size=1, alpha=0.9, width = 0.1)
```

\vspace{2 cm}

\newpage

# Variance by decomposition

Let $X\sim\textrm{Bin}(n,p)$ and $Y\sim\textrm{Bin}(m,p)$. Let $X+Y=r$.

1. Find the variance of $X|r$ by using the variance of a known distribution (See 3.9.2 in the Stat 110 book for a hint).

\vspace{2 cm}

2. Find the variance of $X|r$ by using the fact that $\textrm{Var}(X+Y|r)=0$ and treating $X$ and $Y$ as the sum of Bernoulli random variables. Verify that the two answers are the same. (Hint: Once you get to the Bernoulli random variables, think about how knowing the sum is $r$ makes $p$ irrelevant.)

\vspace{8 cm}

\newpage

# Hypothesis testing on real data

These problems will deal with a dataset of country-level statistics from [UNdata](https://data.un.org/) and [Varieties of Democracy](https://v-dem.net/data/the-v-dem-dataset/).

```{r, echo=F}
# Read in the data
countries <- read.csv("data/country_stats.csv", check.names = F)
```

1. Suppose we want to test for a difference in mean 2010 GDP per capita between democracies and non-democracies. The following plots show the distributions. Which tests would be valid?

```{r, echo=F, fig.width=5, fig.height=3, fig.align='center', cache=T, warning=F}
countries$dem = countries$v2x_polyarchy > 0.5
tmp_countries <- countries[countries$Year == 2010 & !is.na(countries$dem),]

ggplot(tmp_countries, aes(x=`GDP per capita (US dollars)`, fill=dem)) + 
  geom_histogram(alpha=0.4, position="identity", bins = 30) + 
  xlab("GDP per capita") + 
  ylab("Countries") + 
  theme_bw() + 
  labs(fill="Democracy")
```

\vspace{1.5 cm}

2. Perform a formal rank-sum test for the difference in GDP per capita between democracies and non-democracies.

```{r, echo=F}
dem_gdps = countries$`GDP per capita (US dollars)`[countries$Year == 2010 & !is.na(countries$dem) & countries$dem]
nondem_gdps = countries$`GDP per capita (US dollars)`[countries$Year == 2010 & !is.na(countries$dem) & !(countries$dem)]

wilcox.test(dem_gdps, nondem_gdps)
```

\vspace{1.5 cm}

3. Perform a formal log-transformed $t$-test for the difference in GDP per capita between democracies and non-democracies. Give a 95% confidence interval for the ratio of medians.

```{r, echo=F}
t.test(log(dem_gdps), log(nondem_gdps))
```

\vspace{2 cm}

4. Suppose we wanted to test whether there was a difference in the mean number of doctors per country between 2019 and 2020. What would be a good way to do so?

\vspace{1 cm}

5. Perform a formal analysis of variance for the difference in 2010 log GDP per capita by world region.

```{r, echo=F}
countries_2010 <- countries[countries$Year == 2010,]

summary(aov(`GDP per capita (US dollars)`~Region, countries_2010))
```

\vspace{2 cm}

6. Comment on the assumptions of the test.

```{r, echo=F, warning=F}
ggplot(countries_2010, aes(x=Region, y=log10(`GDP per capita (US dollars)`))) + 
  geom_boxplot() + 
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
tmp <- by(log(countries_2010$`GDP per capita (US dollars)`), countries_2010$Region, var, na.rm=T)
df <- data.frame(regions=names(tmp), variances=round(as.vector(tmp), 2),
                 counts=as.vector(table(countries_2010$Region[!is.na(countries_2010$`GDP per capita (US dollars)`)])))
colnames(df) <- c("Region", "Variance", "Number")
df
```

\vspace{2 cm}











