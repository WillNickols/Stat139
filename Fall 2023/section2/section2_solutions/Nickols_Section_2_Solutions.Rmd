---
output:
  pdf_document: default
  html_document:
    df_print: paged
header-includes:
- \usepackage{tcolorbox}
- \usepackage{fancyhdr}
- \usepackage[utf8]{inputenc}
- \usepackage{wrapfig}
- \usepackage{amsmath}
- \usepackage{booktabs}
- \usepackage{esvect}
urlcolor: blue
---

\pagestyle{fancy}
\fancyhf{}
\rhead{Will Nickols}
\lhead{Section 2}
\rfoot{Page \thepage}

# Announcements

\begin{wrapfigure}{r}{0.12\textwidth}
  \centering
    \vspace*{-1.3cm}
    \includegraphics[width=\linewidth]{section_qr_code.png}
\end{wrapfigure}

Make sure to sign in on the [google form](https://forms.gle/xm1DfzuZFNcWU6fH8) (I send a list of which section questions are useful for which pset questions afterwards)

Pset 1 due Friday 9/22

# Introductions (again)
- Name
- One question or thought related to lecture last week ($t$-test, $z$-test, ANOVA, $F$-test)

```{r, echo=F, warning=F, message=F, cache=F}
list.of.packages <- c("ggplot2", "gridExtra", "dplyr")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library(ggplot2)
library(gridExtra)
library(dplyr)
```

# Country demographics

We'll start by making last week's exploratory data analysis a bit more precise. These problems will deal with a data set of country-level statistics from [UNdata](https://data.un.org/) and [Varieties of Democracy](https://v-dem.net/data/the-v-dem-dataset/).


1. We speculated that the Western African and Eastern African countries probably did not have a significant difference in means. Perform a formal $t$-test for the difference in population means between Western African and Eastern African countries. Recall that a formal test includes (1) the hypotheses, (2) the test statistic, (3) the p-value, and (4) the conclusion in the context of the problem.

```{r, echo=F}
countries <- read.csv("data/country_stats.csv", check.names = F)
pop1 <- countries[countries$Year == 2010 & 
                    countries$Region == "Western Africa",
                  ]$`Population mid-year estimates (millions)`

pop2 <- countries[countries$Year == 2010 & 
                    countries$Region == "Eastern Africa",
                  ]$`Population mid-year estimates (millions)`
west_african <- pop1
east_african <- pop2
t.test(west_african, east_african)
```
Let $\mu_0$ be the mean population of countries in Western Africa and $\mu_1$ be the mean population of countries in Eastern Africa. We are testing $H_0$: $\mu_0=\mu_1$ vs $H_a:$ the two means are different. We get a $t$-statistic of $0.12$ with $24.7$ degrees of freedom for a two-sided $t$-test, which corresponds to a p-value of $0.90>0.05$, so we fail to reject the null and do not have sufficient evidence to conclude that the mean populations of Western African and Eastern African countries are different. (The confidence interval for the difference in means is $(-20.0, 22.5)$, which includes 0, consistent with the $t$-test.)

2. Perform a formal $z$-test for the difference in the proportions of the populations that are nurses or midwives in the US versus the UK in 2010.

```{r, echo=F}
us_nurses_midwives <- countries$`Health personnel: Nurses and midwives (number)`[
  countries$Country == "United States of America" & countries$Year ==  2010]
us_pop <- countries$`Population mid-year estimates (millions)`[
  countries$Country == "United States of America" & countries$Year ==  2010] * 1000000
uk_nurses_midwives <- countries$`Health personnel: Nurses and midwives (number)`[
  countries$Country == "United Kingdom" & countries$Year ==  2010]
uk_pop <- countries$`Population mid-year estimates (millions)`[
  countries$Country == "United Kingdom" & countries$Year ==  2010] * 1000000
prop.test(c(us_nurses_midwives, uk_nurses_midwives), c(us_pop, uk_pop), correct = F)
```
Let $p_{\textrm{US}}$ be the proportion of the population that are nurses or midwives in the US and $p_{\textrm{UK}}$ be the equivalent proportion in the UK. We want to test $H_0: p_{\textrm{US}}=p_{\textrm{UK}}$ vs. $H_a:$ they are not equal. We get a $z$-statistic of $\sqrt{57941}=240.7$ which gives a p-value less than $2.2\times10^{-16}$, so we reject the null and conclude that the proportion of the population that are nurses and midwives is significantly higher in the US. Note that `prop.test` performs a $\chi^2$ test, so you need to take the square root of the test statistic to get the $z$-test test statistic.

3. Suppose we wanted to test whether there was a change in the mean number of doctors per country between 2019 and 2020 (e.g., in response to COVID-19). What would be a good way to do so?

We should use a paired $t$-test with pairing by country to check whether the mean difference in countries' doctor numbers between 2020 and 2019 is significantly non-zero. The $t$-test shows that the difference is not quite significant, but only 15 countries have data for both 2020 and 2019, so our test might just have not had enough power.
```{r, echo=F}
df_2019 <- data.frame(country=countries$Country[countries$Year == 2019],
           doctors=countries$`Health personnel: Physicians (number)`[countries$Year == 2019])

df_2020 <- data.frame(country=countries$Country[countries$Year == 2020],
           doctors=countries$`Health personnel: Physicians (number)`[countries$Year == 2020])

joined_df <- full_join(df_2019, df_2020, by=c("country"))
joined_df <- joined_df[rowSums(is.na(joined_df)) == 0,]
colnames(joined_df) <- c("Country", "2019 doctors", "2020 doctors")

t.test(joined_df$`2020 doctors` - joined_df$`2019 doctors`)
```

4. Perform a formal analysis of variance for the difference in 2010 log GDP per capita by world region.

```{r, echo=F}
countries_2010 <- countries[countries$Year == 2010,]

summary(aov(`GDP per capita (US dollars)`~Region, countries_2010))
```
Let $\mu_k$ be the mean GDP per capita of countries in region $k$ (indexed arbitrarily). We want to test $H_0$: $\mu_0=\mu_1=...=\mu_{22}$ vs $H_a$: the means are not all equal. We get an $F$-statistic of 12.84 for 21 and 187 degrees of freedom for a p-value of less than $2\times 10^{-16}$, suggesting that the mean GDPs per capita of different regions are not equal.

5. Comment on the assumptions of the test.

```{r, echo=F, warning=F}
ggplot(countries_2010, aes(x=Region, y=log10(`GDP per capita (US dollars)`))) + 
  geom_boxplot() + 
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
tmp <- by(log(countries_2010$`GDP per capita (US dollars)`), countries_2010$Region, var, na.rm=T)
df <- data.frame(regions=names(tmp), variances=round(as.vector(tmp), 2),
                 counts=as.vector(table(countries_2010$Region[!is.na(countries_2010$`GDP per capita (US dollars)`)])))
colnames(df) <- c("Region", "Variance", "Number of countries")
df
```

The GDPs are about symmetric, so normality is a reasonable assumption. The variances are quite different though (from 0.15 to 2.95; well beyond a 2x difference), so the equal variance assumption is violated. Independence probably does not hold either because the countries likely trade with each other, causing their GDPs to be correlated both within and between groups.

\newpage

# Manipulating new distributions

Let $T_n\sim t_n$. Find the following:

1. Distribution of $T_n^2$. Hint: Think about the representation of $T_n$.

We can represent $T_n$ as $Z/\sqrt{V_n/n}$ where $Z$ is a standard Normal and $V_n$ is a $\chi^2_n$ random variable. Then,

$$T_n^2=Z^2/(V_n/n)=(Z^2/1)/(V_n/n)=F_{1,n}$$

since $Z^2$ has a $\chi^2_1$ distribution and this is our representation of the $F$ random variable.


2. Distribution of $T^{-2}$

$$T_n^{-2}=F_{1,n}^{-1}=F_{n,1}$$

3. Let $X_1,...,X_n\sim\textrm{Expo}(\alpha)$. Find the $k$ (in terms of $\alpha$) such that $k\sum_{i=1}^nX_i\sim\chi^2_{2n}$.

$$2\alpha\sum_{i=1}^nX_i\sim\textrm{Gamma}(n, 1/2)\sim\chi^2_{2n}\implies k=2\alpha$$

\newpage

# Simulations

1. Let $X_1, X_2,\dots, X_n\sim \mathcal{N}(\mu, \sigma^2)$. Then, let $X_{i,1}=X_i+\epsilon_{i,1}$ and $X_{i,2}=X_i+\beta+\epsilon_{i,2}$ with $\epsilon_{i,j}\sim\mathcal{N}(0,\sigma^2)$. Suppose we simulate many paired and unpaired $t$-tests for the difference in the mean of the $X_{i,1}$s vs. the mean of the $X_{i,2}$s. If $\beta$ is non-zero, which color is the paired $t$-test?

```{r, echo=F, fig.width=5, fig.height=3, fig.align='center', cache=T, warning=F}
n = 10
beta = 1
nsim = 1000

paired_vec = vector(length = nsim)
unpaired_vec = vector(length = nsim)
for (i in 1:nsim) {
  x = rnorm(n, 10, 3)
  x_1 = x + rnorm(n, 5, 3)
  x_2 = x + beta + rnorm(n, 0, 3)
  paired_vec[i] = t.test(x_1-x_2)$statistic
  unpaired_vec[i] = t.test(x_1, x_2)$statistic
}

df = data.frame("t-stat" = c(paired_vec, unpaired_vec), 
                "paired" = c(rep("Paired", nsim), rep("Unpaired", nsim)), check.names = F)

ggplot(df, aes(x=`t-stat`, fill=paired)) + 
  geom_histogram(alpha=0.4, position="identity", bins = 30) + 
  theme_bw() + 
  ylab("Count") +
  theme(legend.position = "none")
```

Because this is the proper set-up for a paired $t$-test and there is a difference in means ($\beta\neq0$), the paired $t$-test will have higher power and therefore larger $t$ statistics. Thus, the paired $t$-test is red.

2. Suppose we have some $\beta_i$ for $i\in\{1,...,n_\beta\}$ that are not equal. Let $X_{i,j}=\beta_i+\epsilon_{i,j}$ for $j=1$ to $n$ with $\epsilon_{i,j}\sim\mathcal{N}(0, \sigma^2)$. We want to test whether $\beta_1=\beta_2=\dots=\beta_{n_\beta}$. We'll run a simulation in which we consider two cases:
- In the first case, we use the proper groupings of the $X_{i,j}$; that is, there are $n$ observations in each group, all with the same $\beta_i$.
- In the second case, we'll subdivide each of these groups into 2 so that there are $n/2$ observations in each group with two groups for each $\beta_i$.

We'll run an ANOVA in each case and repeat this many times. Which color is which case?

```{r, echo=F, fig.width=5, fig.height=3, fig.align='center', cache=T, warning=F}
nsim = 1000
n_1 = 10
n_2 = 30
n_3 = 2
betas = 1:n_1

f_correct = vector(length = nsim)
f_incorrect = vector(length = nsim)

for (i in 1:nsim) {
  df = data.frame(matrix(nrow = 0, ncol = 0))
  for (beta in betas) {
    x = beta + rnorm(n_2, 0, 5)
    df = rbind(df, cbind(x, beta))
  }
  df$beta <- as.factor(df$beta)
  f_correct[i] = summary(aov(x~beta, df))[[1]][1,'F value']
  df$beta = as.numeric(as.character(df$beta))
  df$beta = (df$beta - 1) * n_3 + rep(rep(0:(n_3-1), n_2/n_3), n_1)
  df$beta <- as.factor(df$beta)
  f_incorrect[i] = summary(aov(x~beta, df))[[1]][1,'F value']
}

df = data.frame("f-stat" = c(f_correct, f_incorrect), 
                "split" = c(rep("Correct", nsim), rep("Incorrect", nsim)), check.names = F)

ggplot(df, aes(x=`f-stat`, fill=split)) + 
  geom_histogram(alpha=0.4, position="identity", bins=30) + 
  theme_bw() + xlim(0, 30) + 
  ylab("Count") + 
  theme(legend.position = "none")
```

Since the group means in subdivided groups will be similar, the sum of squares within and between groups doesn't change much. However, by increasing the number of groups, we're increasing the degrees of freedom in the between-group part and decreasing the degrees of freedom in the within-group part ($k$ increases):
$$F=\frac{\sum_{i=1}^Kn_i(\bar{Y_i}-\bar{Y})^2/(k-1)}{\sum_{i=1}^K(n_i-1)S_i^2/(n-k)}$$
As $k$ doubles, the $f$-statistic decreases. Thus, the blue is the subdivided groups.

3. Let $X_i\sim\mathcal{N}(0, 1)$ for $i$ from $1$ to $n$. Let $Y_i\sim -1+\textrm{Expo}(1)$ for $i$ from $1$ to $n$. Suppose we conduct a two-sided, one-sample $t$-test for $H_0:\mu=0$ vs. $H_a:\mu\neq 0$ and record the p-value. The plots below show p-values from simulations repeating this many times for the two distributions and $n=5$ or $n=20$. Identify which is which.

```{r, echo=F, fig.width=7, fig.height=3, fig.align='center', cache=T, warning=F}
set.seed(139)
nsims = 200000

out_df <- data.frame(matrix(nrow = 0, ncol = 2))

for (n in c(5, 20)) {
  out_df <- rbind(out_df, cbind(rep(paste0("Normal n=", n), nsims),
                                replicate(nsims, t.test(rnorm(n, 0, 1))$p.value)))
  out_df <- rbind(out_df, cbind(rep(paste0("Expo n=", n), nsims),
                                replicate(nsims, t.test(rexp(n, 1) - 1)$p.value)))
}
out_df <- data.frame(out_df)
colnames(out_df) <- c("Version", "P-value")
out_df$`P-value` <- as.numeric(out_df$`P-value`)

ggplot(out_df, aes(x=`P-value`)) + 
  facet_grid(cols = vars(Version)) + 
  geom_histogram(bins = 20) + 
  xlim(c(0,1)) + 
  theme_bw() + 
  ylab("Count") + 
  theme(strip.text.x = element_blank(),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

The point of this question is to notice that when the $t$-statistic has the $t$ distribution, the p-values will be uniform. The $t$-statistic will have the $t$ distribution by definition if the observations are Normal, so the third and fourth histograms can be either number of Normals. For the exponential distribution, the mean is 0, but the $t$ distribution of the $t$-statistic relies on the Central Limit Theorem, so the larger $n$ will give more uniform p-values. Thus, the first histogram is the exponential case with $n=20$, and the second is the exponential distribution with $n=5$.

4. Which of the two comparisons do you expect to have the lower p-value? The one with a larger difference in sample means or the one with more data points (40 vs 400)?

```{r, echo=F, fig.width=5, fig.height=3, fig.align='center', cache=T, warning=F}
set.seed(9)

df <- data.frame("comparison" = c(rep("Comparison 1", 40), rep("Comparison 2", 400)),
           "group" = c(rep("Group 1", 20), rep("Group 2", 20), rep("Group 1", 200), rep("Group 2", 200)),
           "values" = c(rnorm(20, 5.4, 3), rnorm(20, 6.4, 3), rnorm(200, 5, 3), rnorm(200, 5.5, 3)))

ggplot(df, aes(x=group, y=values)) + 
  facet_grid(cols = vars(comparison)) + 
  geom_boxplot(alpha=0.4, outlier.size = 0) + 
  xlab("Group") + 
  ylab("Value") + 
  theme_bw() + 
  geom_jitter(color="black", size=1, alpha=0.9, width = 0.1)
```

Even though the standard deviations are the same in both, what matters is the standard error, which is much lower in the second because of the increased sample size. The difference in sample means in the second comparison is about half that of the first comparison. However, the standard error of the second comparison is about $\sqrt{40/400}=0.316$ times the standard error of the first comparison, so the $t$-statistic is about 1.58 times as large in the second comparison. Therefore, the second will have the lower p-value.

```{r, cache=T}
# Comparison 1
t.test(df$values[df$group == "Group 1" & df$comparison == "Comparison 1"],
       df$values[df$group == "Group 2" & df$comparison == "Comparison 1"])$p.value

# Comparison 2
t.test(df$values[df$group == "Group 1" & df$comparison == "Comparison 2"],
       df$values[df$group == "Group 2" & df$comparison == "Comparison 2"])$p.value
```











